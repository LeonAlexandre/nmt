python -m nmt.nmt --src=trace --tgt=label --vocab_prefix=./nmt/temp/binary_seq_vocab/vocab --train_prefix=./nmt/temp/data20/data20_0.7/train --dev_prefix=./nmt/temp/data20/data20_0.7/val --test_prefix=./nmt/temp/data20/data20_0.7/test --out_dir=./test-edit --num_train_steps=30000 --steps_per_stats=100 --num_layers=2 --num_units=128 --dropout=0.2 --metrics=edit_distance --share_vocab=True --encoder_type="uni" --steps_per_external_eval=500 --optimizer=adam --learning_rate=0.0001

python -m nmt.nmt --trace0=trace0 --trace1=trace1 --src=trace --tgt=label --vocab_prefix=./nmt/temp/binary_seq_vocab/vocab --train_prefix=./nmt/temp/data20_2t/data0.4/train --dev_prefix=./nmt/temp/data20_2t/data0.4/val --test_prefix=./nmt/temp/data20_2t/data0.4/test --out_dir=./test-edit --num_train_steps=40000 --steps_per_stats=100 --num_layers=2 --num_units=128 --dropout=0.2 --metrics="edit_distance","hamming_distance" --share_vocab=True --encoder_type="uni" --steps_per_external_eval=500 --optimizer=adam --learning_rate=0.0001 --src_max_len=1000 --tgt_max_len=1000 --num_traces=2

python -m nmt.nmt --src=trace --tgt=label --vocab_prefix=./nmt/temp/binary_seq_vocab/vocab --train_prefix=./nmt/temp/data20_2t/data0.4/train --dev_prefix=./nmt/temp/data20_2t/data0.4/val --test_prefix=./nmt/temp/data20_2t/data0.4/test --out_dir=./nmt/temp/Benchmark20_2encoder_beam2/model0.4 --num_train_steps=50000 --steps_per_stats=100 --num_layers=2 --num_units=128 --dropout=0.2 --metrics=edit_distance,hamming_distance --share_vocab=True --encoder_type="uni" --steps_per_external_eval=500 --optimizer=adam --learning_rate=0.0001 --src_max_len=20 --src_max_len_infer=20 --num_traces=2 --beam_width=2

start detachable screen: screen 
to detach: ctrl-a ctrl-d
to resume: screen -r
to kill all detached screens: screen -ls | grep pts | cut -d. -f1 | awk '{print $1}' | xargs kill

git pull
git add --all
git commit -m "completed benchmark20 2encoder beam2 0.1"
git push