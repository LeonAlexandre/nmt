python -m nmt.nmt --src=trace --tgt=label --vocab_prefix=./nmt/temp/binary_seq_vocab/vocab --train_prefix=./nmt/temp/data20/data20_0.7/train --dev_prefix=./nmt/temp/data20/data20_0.7/val --test_prefix=./nmt/temp/data20/data20_0.7/test --out_dir=./test-edit --num_train_steps=30000 --steps_per_stats=100 --num_layers=2 --num_units=128 --dropout=0.2 --metrics=edit_distance --share_vocab=True --encoder_type="uni" --steps_per_external_eval=500 --optimizer=adam --learning_rate=0.0001

python -m nmt.nmt --trace0=trace0 --trace1=trace1 --src=trace --tgt=label --vocab_prefix=./nmt/temp/binary_seq_vocab/vocab --train_prefix=./nmt/temp/data20_2t/data0.4/train --dev_prefix=./nmt/temp/data20_2t/data0.4/val --test_prefix=./nmt/temp/data20_2t/data0.4/test --out_dir=./test-edit --num_train_steps=40000 --steps_per_stats=100 --num_layers=2 --num_units=128 --dropout=0.2 --metrics="edit_distance","hamming_distance" --share_vocab=True --encoder_type="uni" --steps_per_external_eval=500 --optimizer=adam --learning_rate=0.0001 --src_max_len=1000 --tgt_max_len=1000 --num_traces=2


start detachable screen: screen 
to detach: ctrl-a ctrl-d
to resume: screen -r
to kill all detached screens: screen -ls | grep pts | cut -d. -f1 | awk '{print $1}' | xargs kill

git pull
git add --all
git commit -m "completed benchmark20 2 encoder 0.2"
git push


src_tgt_dataset shapes 2-encoder (hard code):

src_tgt_dataset after zip: <ZipDataset shapes: ((), (), ()), types: (tf.string, tf.string, tf.string)>
src_tgt_dataset before split: <ShuffleDataset shapes: ((), (), ()), types: (tf.string, tf.string, tf.string)>
src_tgt_dataset after split: <PrefetchDataset shapes: ((?,), (?,), (?,)), types: (tf.string, tf.string, tf.string)>
src_tgt_dataset after zero len filter: <FilterDataset shapes: ((?,), (?,), (?,)), types: (tf.string, tf.string, tf.string)>
src_tgt_dataset after src_max_len cutoff: <PrefetchDataset shapes: ((?,), (?,), (?,)), types: (tf.string, tf.string, tf.string)>
src_tgt_dataset after tgt_max_len cutoff: <PrefetchDataset shapes: ((?,), (?,), (?,)), types: (tf.string, tf.string, tf.string)>
src_tgt_dataset after vocab lookup: <PrefetchDataset shapes: ((?,), (?,), (?,)), types: (tf.int32, tf.int32, tf.int32)>
src_tgt_dataset after tgt prefix/suffix: <PrefetchDataset shapes: ((?,), (?,), (?,), (?,)), types: (tf.int32, tf.int32, tf.int32, tf.int32)>
src_tgt_dataset after adding seq lens: <PrefetchDataset shapes: ((?,), (?,), (?,), (?,), (), (), ()), types: (tf.int32, tf.int32, tf.int32, tf.int32, tf.int32, tf.int32, tf.int32)>
batched_dataset: <PaddedBatchDataset shapes: ((?, ?), (?, ?), (?, ?), (?, ?), (?,), (?,), (?,)), types: (tf.int32, tf.int32, tf.int32, tf.int32, tf.int32, tf.int32, tf.int32)>
batched_iter: <tensorflow.python.data.ops.iterator_ops.Iterator object at 0x7f0a656eb748>
BatchedInputIter: BatchedInput2t(initializer=<tf.Operation 'MakeIterator' type=MakeIterator>, trace0=<tf.Tensor 'IteratorGetNext:0' shape=(?, ?) dtype=int32>, trace1=<tf.Tensor 'IteratorGetNext:1' shape=(?, ?) dtype=int32>, target_input=<tf.Tensor 'IteratorGetNext:2' shape=(?, ?) dtype=int32>, target_output=<tf.Tensor 'IteratorGetNext:3' shape=(?, ?) dtype=int32>, trace0_sequence_length=<tf.Tensor 'IteratorGetNext:4' shape=(?,) dtype=int32>, trace1_sequence_length=<tf.Tensor 'IteratorGetNext:5' shape=(?,) dtype=int32>, target_sequence_length=<tf.Tensor 'IteratorGetNext:6' shape=(?,) dtype=int32>)

src_tgt_dataset shapes N-encoder (N=2):

src_tgt_dataset after zip: <ZipDataset shapes: ((), (), ()), types: (tf.string, tf.string, tf.string)>
src_tgt_dataset before split: <ShuffleDataset shapes: ((), (), ()), types: (tf.string, tf.string, tf.string)>
src_tgt_dataset after split: <PrefetchDataset shapes: ((?,), (?,), (?,)), types: (tf.string, tf.string, tf.string)>
src_tgt_dataset after zero len filter: <FilterDataset shapes: ((?,), (?,), (?,)), types: (tf.string, tf.string, tf.string)>
src_tgt_dataset after src_max_len cutoff: <PrefetchDataset shapes: ((?,), (?,), (?,)), types: (tf.string, tf.string, tf.string)>
src_tgt_dataset after tgt_max_len cutoff: <PrefetchDataset shapes: ((?,), (?,), (?,)), types: (tf.string, tf.string, tf.string)>
src_tgt_dataset after vocab lookup: <PrefetchDataset shapes: ((?,), (?,), (?,)), types: (tf.int32, tf.int32, tf.int32)>
src_tgt_dataset after tgt prefix/suffix: <PrefetchDataset shapes: ((?,), (?,), (?,), (?,)), types: (tf.int32, tf.int32, tf.int32, tf.int32)>
src_tgt_dataset after adding seq lens: <PrefetchDataset shapes: ((?,), (?,), (?,), (?,), (), (), ()), types: (tf.int32, tf.int32, tf.int32, tf.int32, tf.int32, tf.int32, tf.int32)>
batched_dataset: <PaddedBatchDataset shapes: ((?, ?), (?, ?), (?, ?), (?, ?), (?,), (?,), (?,)), types: (tf.int32, tf.int32, tf.int32, tf.int32, tf.int32, tf.int32, tf.int32)>
batched_iter: <tensorflow.python.data.ops.iterator_ops.Iterator object at 0x7f5994e9a518>
BatchedInputIter: BatchedInput2t(initializer=<tf.Operation 'MakeIterator' type=MakeIterator>, trace0=<tf.Tensor 'IteratorGetNext:0' shape=(?, ?) dtype=int32>, trace1=<tf.Tensor 'IteratorGetNext:1' shape=(?, ?) dtype=int32>, target_input=<tf.Tensor 'IteratorGetNext:2' shape=(?, ?) dtype=int32>, target_output=<tf.Tensor 'IteratorGetNext:3' shape=(?, ?) dtype=int32>, trace0_sequence_length=<tf.Tensor 'IteratorGetNext:4' shape=(?,) dtype=int32>, trace1_sequence_length=<tf.Tensor 'IteratorGetNext:5' shape=(?,) dtype=int32>, target_sequence_length=<tf.Tensor 'IteratorGetNext:6' shape=(?,) dtype=int32>)
